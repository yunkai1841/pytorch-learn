# Autograd
ニューラルネットワークを学習させるとき、逆伝播アルゴリズムでは、ネットワークのパラメータに対する損失関数の勾配を計算する。これは、ネットワークのパラメータを更新するために必要である。PyTorchでは、`autograd`パッケージがこの自動微分の計算を行う。`autograd`パッケージは、Tensorのすべての演算に対して勾配を自動的に計算する。このパッケージは、ネットワークの学習を定義するために、`Tensor`の演算を記録することで動作する。この記録を用いて、最終的な勾配を計算するために、`backward()`メソッドを呼び出すことができる。この`backward()`メソッドは、勾配を計算するために、`Tensor`の`grad_fn`属性を辿ることで動作する。`Tensor`がユーザーによって作成された場合、`grad_fn`は`None`である。